I"£<ul>
  <li>K-means clustering aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean.</li>
  <li>If you want to separate different car models into 4 categories based on horsepower, engine displacement, and MPG, you can use K-means.</li>
  <li>KNN is unsupervised learning and a clustering algorithm (involves the grouping of data points).</li>
  <li>K represents # of centroids.
<img src="k-means.png" alt="" /></li>
</ul>

<p>Figure Credit: https://blogs.oracle.com/bigdata/k-means-clustering-machine-learning</p>

<h4 id="an-example">An Example</h4>
<p><img src="k-means2.png" alt="" /></p>

<p>Example is based on: https://www.youtube.com/watch?v=4b5d3muPQmA</p>

<h3 id="k-means-advantages-vs-disadvantages">K-Means: Advantages vs Disadvantages</h3>
<h4 id="advantages">Advantages:</h4>
<ul>
  <li>Easy to implement.</li>
  <li>K-means model dynamically updated: centroid can be updated if new dataset is added.</li>
</ul>

<h4 id="disadvantages">Disadvantages:</h4>
<ul>
  <li>Hard to guess K</li>
  <li>Initial centroid can impact results</li>
  <li>K-means is time consuming. Need to calculate distances between new centroid in every loop.</li>
  <li>K-means method may not find out the global best solution. It sometimes returns local optimum.</li>
  <li>K-means is limited to linear cluster boundaries.</li>
</ul>

<table>
  <tbody>
    <tr>
      <td>Â </td>
      <td><a href="../../">Index</a></td>
      <td>Â </td>
      <td>Â </td>
      <td><a href="../">Prev</a></td>
      <td>Â </td>
      <td>Â </td>
      <td><a href="k-means-algo">Next</a></td>
      <td>Â </td>
      <td>Â </td>
    </tr>
  </tbody>
</table>
:ET